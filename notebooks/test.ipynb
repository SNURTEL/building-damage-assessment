{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pprint import pprint\n",
    "import importlib\n",
    "import hydra\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Any, Callable\n",
    "\n",
    "import dotenv\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "import torchmetrics.classification\n",
    "import torchmetrics.segmentation\n",
    "from matplotlib import pyplot as plt\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, RichProgressBar\n",
    "from simplecv.module import fpn\n",
    "from torch import Tensor\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from inz.models.base_pl_module import BasePLModule\n",
    "from inz.data.data_module import XBDDataModule\n",
    "from inz.data.event import Event, Hold, Test, Tier1, Tier3\n",
    "from inz.util import get_wandb_logger, show_masks_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inz.models.farseg_module import DoubleBranchFarSegModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 123\n"
     ]
    }
   ],
   "source": [
    "dotenv.load_dotenv()\n",
    "RANDOM_SEED = 123\n",
    "pl.seed_everything(RANDOM_SEED)\n",
    "device = torch.device(\"cuda\")\n",
    "torch.set_float32_matmul_precision(\"high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CKPT_PATH =\"/home/tomek/inz/inz/saved_checkpoints/farseg_doublebranch-epoch-39-step-39000-f1-0.660326-best-f1.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simplecv.util.logger:ResNetEncoder: pretrained = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene_relation: on\n",
      "loss type: cosine\n"
     ]
    }
   ],
   "source": [
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "with initialize(version_base=\"1.3\", config_path=\"../outputs/farseg_tier1_tier3/2024-10-21_09-20-16/.hydra\"):\n",
    "    cfg = compose(config_name=\"config\", overrides=[])\n",
    "\n",
    "model_class_str = cfg[\"module\"][\"module\"][\"_target_\"]\n",
    "model_class_name = model_class_str.split(\".\")[-1]\n",
    "module_path = \".\".join(model_class_str.split(\".\")[:-1])\n",
    "imported_module = importlib.import_module(module_path)\n",
    "model_class = getattr(imported_module, model_class_name)\n",
    "model_partial = hydra.utils.instantiate(cfg[\"module\"][\"module\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DoubleBranchFarSegModule(\n",
       "  (model): DoubleBranchFarSeg(\n",
       "    (module): FarSeg(\n",
       "      (en): ResNetEncoder(\n",
       "        (resnet): ResNet(\n",
       "          (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "          (layer1): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (layer2): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "            (3): Bottleneck(\n",
       "              (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (layer3): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "            (3): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "            (4): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "            (5): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (layer4): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (fpn): FPN(\n",
       "        (fpn_inner1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fpn_layer1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (fpn_inner2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fpn_layer2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (fpn_inner3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fpn_layer3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (fpn_inner4): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fpn_layer4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (decoder): AssymetricDecoder(\n",
       "        (blocks): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "              (3): Identity()\n",
       "            )\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "              (3): UpsamplingBilinear2d(scale_factor=2.0, mode='bilinear')\n",
       "            )\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "              (3): UpsamplingBilinear2d(scale_factor=2.0, mode='bilinear')\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "              (3): UpsamplingBilinear2d(scale_factor=2.0, mode='bilinear')\n",
       "            )\n",
       "          )\n",
       "          (3): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "              (3): UpsamplingBilinear2d(scale_factor=2.0, mode='bilinear')\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "              (3): UpsamplingBilinear2d(scale_factor=2.0, mode='bilinear')\n",
       "            )\n",
       "            (2): Sequential(\n",
       "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "              (3): UpsamplingBilinear2d(scale_factor=2.0, mode='bilinear')\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (cls_pred_conv): Conv2d(128, 5, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (upsample4x_op): UpsamplingBilinear2d(scale_factor=4.0, mode='bilinear')\n",
       "      (gap): AdaptiveAvgPool2d(output_size=1)\n",
       "      (sr): SceneRelation(\n",
       "        (scene_encoder): ModuleList(\n",
       "          (0-3): 4 x Sequential(\n",
       "            (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (content_encoders): ModuleList(\n",
       "          (0-3): 4 x Sequential(\n",
       "            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (feature_reencoders): ModuleList(\n",
       "          (0-3): 4 x Sequential(\n",
       "            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (normalizer): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (outconv): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (accuracy_loc): BinaryAccuracy()\n",
       "  (iou_loc): MeanIoU()\n",
       "  (f1): MulticlassF1Score()\n",
       "  (precision): MulticlassPrecision()\n",
       "  (recall): MulticlassRecall()\n",
       "  (iou): MeanIoU()\n",
       "  (f1_per_class): MulticlassF1Score()\n",
       "  (precision_per_class): MulticlassPrecision()\n",
       "  (recall_per_class): MulticlassRecall()\n",
       "  (iou_per_class): MeanIoU()\n",
       "  (f1_loc): BinaryF1Score()\n",
       "  (accuracy_loc_safe): BinaryAccuracy()\n",
       "  (iou_loc_safe): MeanIoU()\n",
       "  (f1_safe): MulticlassF1Score()\n",
       "  (precision_safe): MulticlassPrecision()\n",
       "  (recall_safe): MulticlassRecall()\n",
       "  (iou_safe): MeanIoU()\n",
       "  (f1_per_class_safe): MulticlassF1Score()\n",
       "  (precision_per_class_safe): MulticlassPrecision()\n",
       "  (recall_per_class_safe): MulticlassRecall()\n",
       "  (iou_per_class_safe): MeanIoU()\n",
       "  (f1_loc_safe): BinaryF1Score()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DoubleBranchFarSegModule.load_from_checkpoint(CKPT_PATH, *model_partial.args, **model_partial.keywords).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117 test batches\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "dm = XBDDataModule(\n",
    "    path=Path(\"data/xBD_processed_512\"),\n",
    "    drop_unclassified_channel=True,\n",
    "    events={\n",
    "        Hold: [\n",
    "            Event.guatemala_volcano,\n",
    "            Event.hurricane_florence,\n",
    "            Event.hurricane_harvey,\n",
    "            Event.hurricane_matthew,\n",
    "            Event.hurricane_michael,\n",
    "            Event.mexico_earthquake,\n",
    "            Event.midwest_flooding,\n",
    "            Event.palu_tsunami,\n",
    "            Event.santa_rosa_wildfire,\n",
    "            Event.socal_fire,\n",
    "        ],\n",
    "    },\n",
    "    val_fraction=0.0,\n",
    "    test_fraction=1.0,\n",
    "    train_batch_size=BATCH_SIZE,\n",
    "    val_batch_size=BATCH_SIZE,\n",
    "    test_batch_size=BATCH_SIZE,\n",
    "    # transform=T.Compose(\n",
    "    #     transforms=[\n",
    "    #         T.RandomHorizontalFlip(p=0.5),\n",
    "    #         T.RandomApply(\n",
    "    #             p=0.6, transforms=[T.RandomAffine(degrees=(-10, 10), scale=(0.9, 1.1), translate=(0.1, 0.1))]\n",
    "    #         ),\n",
    "    #     ]\n",
    "    # ),\n",
    ")\n",
    "dm.prepare_data()\n",
    "dm.setup(\"test\")\n",
    "\n",
    "print(f\"{len(dm.test_dataloader())} test batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomek/inz/inz/.venv/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=bf16` is supported for historical reasons but its usage is discouraged. Please set your precision to bf16-mixed instead!\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdff000512b14d318645b76ccd67264d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          acc_loc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9842587113380432     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     accuracy_loc_safe     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9842584729194641     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      challenge_score      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.650323748588562     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   challenge_score_safe    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7461757063865662     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">            f1             </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6866701245307922     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           f1_0            </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9916307926177979     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         f1_0_safe         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.991671085357666     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           f1_1            </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8104465007781982     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         f1_1_safe         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8182202577590942     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           f1_2            </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4231886863708496     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         f1_2_safe         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4829452633857727     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           f1_3            </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5836737751960754     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         f1_3_safe         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6655851602554321     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           f1_4            </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6244109869003296     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         f1_4_safe         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.739401638507843     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         f1_class          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5619321465492249     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       f1_class_safe       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6987071633338928     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          f1_loc           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8565713167190552     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        f1_loc_safe        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8569356203079224     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          f1_safe          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7395646572113037     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">            iou            </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.28329113125801086    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           iou_0           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9802424311637878     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        iou_0_safe         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9802618622779846     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           iou_1           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2626893222332001     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        iou_1_safe         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.26292744278907776    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           iou_2           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.041807446628808975    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        iou_2_safe         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.04183216765522957    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           iou_3           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06591569632291794    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        iou_3_safe         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06611308455467224    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           iou_4           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06580130010843277    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        iou_4_safe         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06589502841234207    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          iou_loc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6999634504318237     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       iou_loc_safe        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7000450491905212     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         iou_safe          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2834058701992035     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         precision         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7344251275062561     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        precision_0        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9892022013664246     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     precision_0_safe      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9892467856407166     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        precision_1        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8475274443626404     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     precision_1_safe      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8547393679618835     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        precision_2        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.48553794622421265    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     precision_2_safe      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5156727433204651     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        precision_3        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.60467928647995      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     precision_3_safe      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6571760773658752     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        precision_4        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7451770901679993     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     precision_4_safe      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8304082751274109     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      precision_safe       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7694486379623413     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          recall           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6704961061477661     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         recall_0          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9940763711929321     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       recall_0_safe       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9941072463989258     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         recall_1          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7799804210662842     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       recall_1_safe       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7846938967704773     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         recall_2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4207552373409271     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       recall_2_safe       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4541240334510803     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         recall_3          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5933434963226318     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       recall_3_safe       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6742122173309326     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         recall_4          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5643253922462463     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       recall_4_safe       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6663721799850464     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        recall_safe        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7147018909454346     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.062313638627529144    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        val_loss_0         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        val_loss_1         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        val_loss_2         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        val_loss_3         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        val_loss_4         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         acc_loc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9842587113380432    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    accuracy_loc_safe    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9842584729194641    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     challenge_score     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.650323748588562    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m  challenge_score_safe   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7461757063865662    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m           f1            \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6866701245307922    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m          f1_0           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9916307926177979    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        f1_0_safe        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.991671085357666    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m          f1_1           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8104465007781982    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        f1_1_safe        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8182202577590942    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m          f1_2           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4231886863708496    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        f1_2_safe        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4829452633857727    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m          f1_3           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5836737751960754    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        f1_3_safe        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6655851602554321    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m          f1_4           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6244109869003296    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        f1_4_safe        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.739401638507843    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        f1_class         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5619321465492249    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      f1_class_safe      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6987071633338928    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         f1_loc          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8565713167190552    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       f1_loc_safe       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8569356203079224    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         f1_safe         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7395646572113037    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m           iou           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.28329113125801086   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m          iou_0          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9802424311637878    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       iou_0_safe        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9802618622779846    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m          iou_1          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2626893222332001    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       iou_1_safe        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.26292744278907776   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m          iou_2          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.041807446628808975   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       iou_2_safe        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.04183216765522957   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m          iou_3          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06591569632291794   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       iou_3_safe        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06611308455467224   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m          iou_4          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06580130010843277   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       iou_4_safe        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06589502841234207   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         iou_loc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6999634504318237    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      iou_loc_safe       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7000450491905212    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        iou_safe         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2834058701992035    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        precision        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7344251275062561    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       precision_0       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9892022013664246    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    precision_0_safe     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9892467856407166    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       precision_1       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8475274443626404    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    precision_1_safe     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8547393679618835    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       precision_2       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.48553794622421265   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    precision_2_safe     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5156727433204651    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       precision_3       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.60467928647995     \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    precision_3_safe     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6571760773658752    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       precision_4       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7451770901679993    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    precision_4_safe     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8304082751274109    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     precision_safe      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7694486379623413    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         recall          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6704961061477661    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        recall_0         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9940763711929321    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      recall_0_safe      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9941072463989258    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        recall_1         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7799804210662842    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      recall_1_safe      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7846938967704773    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        recall_2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4207552373409271    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      recall_2_safe      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4541240334510803    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        recall_3         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5933434963226318    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      recall_3_safe      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6742122173309326    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        recall_4         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5643253922462463    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      recall_4_safe      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6663721799850464    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       recall_safe       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7147018909454346    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.062313638627529144   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       val_loss_0        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       val_loss_1        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       val_loss_2        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       val_loss_3        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       val_loss_4        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'acc_loc': 0.9842587113380432,\n",
       "  'iou_loc': 0.6999634504318237,\n",
       "  'f1': 0.6866701245307922,\n",
       "  'precision': 0.7344251275062561,\n",
       "  'recall': 0.6704961061477661,\n",
       "  'iou': 0.28329113125801086,\n",
       "  'f1_0': 0.9916307926177979,\n",
       "  'f1_1': 0.8104465007781982,\n",
       "  'f1_2': 0.4231886863708496,\n",
       "  'f1_3': 0.5836737751960754,\n",
       "  'f1_4': 0.6244109869003296,\n",
       "  'precision_0': 0.9892022013664246,\n",
       "  'precision_1': 0.8475274443626404,\n",
       "  'precision_2': 0.48553794622421265,\n",
       "  'precision_3': 0.60467928647995,\n",
       "  'precision_4': 0.7451770901679993,\n",
       "  'recall_0': 0.9940763711929321,\n",
       "  'recall_1': 0.7799804210662842,\n",
       "  'recall_2': 0.4207552373409271,\n",
       "  'recall_3': 0.5933434963226318,\n",
       "  'recall_4': 0.5643253922462463,\n",
       "  'iou_0': 0.9802424311637878,\n",
       "  'iou_1': 0.2626893222332001,\n",
       "  'iou_2': 0.041807446628808975,\n",
       "  'iou_3': 0.06591569632291794,\n",
       "  'iou_4': 0.06580130010843277,\n",
       "  'val_loss_0': 0.0,\n",
       "  'val_loss_1': 0.0,\n",
       "  'val_loss_2': 0.0,\n",
       "  'val_loss_3': 0.0,\n",
       "  'val_loss_4': 0.0,\n",
       "  'val_loss': 0.062313638627529144,\n",
       "  'f1_class': 0.5619321465492249,\n",
       "  'f1_loc': 0.8565713167190552,\n",
       "  'challenge_score': 0.650323748588562,\n",
       "  'accuracy_loc_safe': 0.9842584729194641,\n",
       "  'iou_loc_safe': 0.7000450491905212,\n",
       "  'f1_safe': 0.7395646572113037,\n",
       "  'precision_safe': 0.7694486379623413,\n",
       "  'recall_safe': 0.7147018909454346,\n",
       "  'iou_safe': 0.2834058701992035,\n",
       "  'f1_loc_safe': 0.8569356203079224,\n",
       "  'f1_0_safe': 0.991671085357666,\n",
       "  'f1_1_safe': 0.8182202577590942,\n",
       "  'f1_2_safe': 0.4829452633857727,\n",
       "  'f1_3_safe': 0.6655851602554321,\n",
       "  'f1_4_safe': 0.739401638507843,\n",
       "  'precision_0_safe': 0.9892467856407166,\n",
       "  'precision_1_safe': 0.8547393679618835,\n",
       "  'precision_2_safe': 0.5156727433204651,\n",
       "  'precision_3_safe': 0.6571760773658752,\n",
       "  'precision_4_safe': 0.8304082751274109,\n",
       "  'recall_0_safe': 0.9941072463989258,\n",
       "  'recall_1_safe': 0.7846938967704773,\n",
       "  'recall_2_safe': 0.4541240334510803,\n",
       "  'recall_3_safe': 0.6742122173309326,\n",
       "  'recall_4_safe': 0.6663721799850464,\n",
       "  'iou_0_safe': 0.9802618622779846,\n",
       "  'iou_1_safe': 0.26292744278907776,\n",
       "  'iou_2_safe': 0.04183216765522957,\n",
       "  'iou_3_safe': 0.06611308455467224,\n",
       "  'iou_4_safe': 0.06589502841234207,\n",
       "  'f1_class_safe': 0.6987071633338928,\n",
       "  'challenge_score_safe': 0.7461757063865662}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=1,\n",
    "    callbacks=[\n",
    "        RichProgressBar()\n",
    "    ],\n",
    "    precision=\"bf16\",\n",
    "    # TODO logger?\n",
    ")\n",
    "trainer.test(model, datamodule=dm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
