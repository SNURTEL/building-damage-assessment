{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import mlflow\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, RichProgressBar\n",
    "from pytorch_lightning.loggers import MLFlowLogger\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inz.data.data_module import XBDDataModule\n",
    "from inz.data.event import Event, Tier3, Tier1, Hold, Test\n",
    "from inz.models.unet_siamese import UNetSiamese\n",
    "from inz.models.unet_siamese_pl import (\n",
    "    OrdinalCrossEntropyLoss,\n",
    "    SemanticSegmentorSiamese,\n",
    "    FocalLoss,\n",
    "    DiceLoss,\n",
    "    CrossEntropyDiceLoss,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 123\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 123\n",
    "pl.seed_everything(RANDOM_SEED)\n",
    "device = torch.device(\"cuda\")\n",
    "torch.set_float32_matmul_precision(\"high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85 train batches, 15 val batches\n"
     ]
    }
   ],
   "source": [
    "dm = XBDDataModule(\n",
    "    path=Path(\"data/xBD_processed\"),\n",
    "    events={\n",
    "        # Tier1: [\n",
    "        #     Event.hurricane_florence,\n",
    "        #     Event.hurricane_harvey,\n",
    "        #     Event.hurricane_matthew,\n",
    "        #     Event.hurricane_michael,\n",
    "        # ],\n",
    "        Tier3: [\n",
    "            Event.joplin_tornado,\n",
    "            #     # Event.moore_tornado,\n",
    "            #     # Event.tuscaloosa_tornado\n",
    "        ],\n",
    "        # Hold: [\n",
    "        #     Event.hurricane_florence,\n",
    "        #     Event.hurricane_harvey,\n",
    "        #     Event.hurricane_matthew,\n",
    "        #     Event.hurricane_michael,\n",
    "        # ],\n",
    "        # Test: [\n",
    "        #     Event.hurricane_florence,\n",
    "        #     Event.hurricane_harvey,\n",
    "        #     Event.hurricane_matthew,\n",
    "        #     Event.hurricane_michael,\n",
    "        # ],\n",
    "    },\n",
    "    val_faction=0.15,\n",
    "    test_fraction=0.0,\n",
    "    train_batch_size=24,\n",
    "    val_batch_size=24,\n",
    "    test_batch_size=24,\n",
    "    # split_events={\n",
    "    #     \"train\": {\n",
    "    #         Tier1: [\n",
    "    #             # Event.hurricane_florence,\n",
    "    #             # Event.hurricane_harvey,\n",
    "    #             # Event.hurricane_matthew,\n",
    "    #             # Event.hurricane_michael,\n",
    "    #         ],\n",
    "    #         Tier3: [\n",
    "    #             Event.joplin_tornado,\n",
    "    #             Event.moore_tornado,\n",
    "    #             Event.tuscaloosa_tornado\n",
    "    #         ],\n",
    "    #     },\n",
    "    #     \"val\": {\n",
    "    #         Hold: [\n",
    "    #             # Event.hurricane_florence,\n",
    "    #             # Event.hurricane_harvey,\n",
    "    #             Event.hurricane_matthew,\n",
    "    #             # Event.hurricane_michael,\n",
    "    #         ],\n",
    "    #         Test: [\n",
    "    #             # Event.hurricane_florence,\n",
    "    #             # Event.hurricane_harvey,\n",
    "    #             Event.hurricane_matthew,\n",
    "    #             # Event.hurricane_michael,\n",
    "    #         ],\n",
    "    #     },\n",
    "    # },\n",
    ")\n",
    "dm.prepare_data()\n",
    "dm.setup(\"fit\")\n",
    "\n",
    "print(f\"{len(dm.train_dataloader())} train batches, {len(dm.val_dataloader())} val batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [00:20<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.1890e+08, 7.7670e+06, 2.1349e+06, 1.3483e+06, 2.4458e+06, 2.4971e+05])\n",
      "Localization weights: tensor([0.1052, 0.8948], device='cuda:0')\n",
      "Classification weights: tensor([0.0015, 0.0223, 0.0813, 0.1287, 0.0710, 0.0000], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "aaa_loc = []\n",
    "aaa_cls = []\n",
    "for batch in tqdm(dm.train_dataloader()):\n",
    "    pre_images, pre_masks, post_images, post_masks = batch\n",
    "    counts_post = torch.bincount(post_masks.argmax(dim=1).reshape(-1), minlength=6)\n",
    "    aaa_cls.append(counts_post)\n",
    "    counts_pre = torch.bincount(pre_masks.argmax(dim=1).reshape(-1), minlength=6)\n",
    "    aaa_loc.append(torch.tensor([counts_pre[0], counts_pre[1:].sum()]))\n",
    "\n",
    "loc_counts = torch.stack(aaa_loc).sum(dim=0).to(torch.float)\n",
    "cls_counts = torch.stack(aaa_cls).sum(dim=0).to(torch.float)\n",
    "\n",
    "print(cls_counts)\n",
    "\n",
    "loc_weights = loc_counts.sum() / loc_counts\n",
    "loc_weights = (loc_weights / loc_weights.sum()).cuda()\n",
    "cls_weights = cls_counts.sum() / cls_counts\n",
    "cls_weights = (cls_weights / cls_weights.sum()).cuda() * torch.tensor(\n",
    "    [1, 1, 1, 1, 1, 0]\n",
    ").cuda()  # last class is \"unclassified\"\n",
    "\n",
    "print(f\"Localization weights: {loc_weights}\\nClassification weights: {cls_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomek/inz/inz/.venv/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "/home/tomek/inz/inz/.venv/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'localization_loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['localization_loss'])`.\n",
      "/home/tomek/inz/inz/.venv/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'classification_loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['classification_loss'])`.\n"
     ]
    }
   ],
   "source": [
    "model = SemanticSegmentorSiamese(\n",
    "    model=UNetSiamese(in_channels=3, out_channels=6),\n",
    "    localization_loss=FocalLoss(reduction=\"mean\", weight=loc_weights[1]),\n",
    "    # localization_loss=torch.nn.BCEWithLogitsLoss(pos_weight=loc_weights[1]),\n",
    "    classification_loss=CrossEntropyDiceLoss(weights=cls_weights, reduction=\"mean\"),\n",
    "    # classification_loss=OrdinalCrossEntropyLoss(n_classes=6, weights=cls_weights),\n",
    "    n_classes=6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomek/inz/inz/.venv/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=bf16` is supported for historical reasons but its usage is discouraged. Please set your precision to bf16-mixed instead!\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "2024/06/12 11:52:09 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'be77ae391c2c4c3485f1f18ab4c7838a', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "/home/tomek/inz/inz/.venv/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:44: attribute 'localization_loss' removed from hparams because it cannot be pickled\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">    </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name                </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                 </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0  </span>│ model               │ UNetSiamese          │  145 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1  </span>│ localization_loss   │ FocalLoss            │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2  </span>│ classification_loss │ CrossEntropyDiceLoss │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3  </span>│ accuracy_loc        │ BinaryAccuracy       │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4  </span>│ iou_loc             │ MeanIoU              │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5  </span>│ f1                  │ MulticlassF1Score    │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6  </span>│ precision           │ MulticlassPrecision  │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7  </span>│ recall              │ MulticlassRecall     │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8  </span>│ iou                 │ MeanIoU              │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9  </span>│ f1_per_class        │ MulticlassF1Score    │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 10 </span>│ precision_per_class │ MulticlassPrecision  │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 11 </span>│ recall_per_class    │ MulticlassRecall     │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 12 </span>│ iou_per_class       │ MeanIoU              │      0 │\n",
       "└────┴─────────────────────┴──────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m  \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName               \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0 \u001b[0m\u001b[2m \u001b[0m│ model               │ UNetSiamese          │  145 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1 \u001b[0m\u001b[2m \u001b[0m│ localization_loss   │ FocalLoss            │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2 \u001b[0m\u001b[2m \u001b[0m│ classification_loss │ CrossEntropyDiceLoss │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3 \u001b[0m\u001b[2m \u001b[0m│ accuracy_loc        │ BinaryAccuracy       │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m4 \u001b[0m\u001b[2m \u001b[0m│ iou_loc             │ MeanIoU              │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m5 \u001b[0m\u001b[2m \u001b[0m│ f1                  │ MulticlassF1Score    │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m6 \u001b[0m\u001b[2m \u001b[0m│ precision           │ MulticlassPrecision  │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m7 \u001b[0m\u001b[2m \u001b[0m│ recall              │ MulticlassRecall     │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m8 \u001b[0m\u001b[2m \u001b[0m│ iou                 │ MeanIoU              │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m9 \u001b[0m\u001b[2m \u001b[0m│ f1_per_class        │ MulticlassF1Score    │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m10\u001b[0m\u001b[2m \u001b[0m│ precision_per_class │ MulticlassPrecision  │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m11\u001b[0m\u001b[2m \u001b[0m│ recall_per_class    │ MulticlassRecall     │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m12\u001b[0m\u001b[2m \u001b[0m│ iou_per_class       │ MeanIoU              │      0 │\n",
       "└────┴─────────────────────┴──────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 145 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 145 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 580                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 145 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 145 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 580                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "866c84a081794397a1a7827aebde4c50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 85: 'f1' reached 0.29326 (best 0.29326), saving model to './mlruns/124960261813571015/5801385d6f0245a7b11b53c65fbc3e14/checkpoints/f1_epoch=0f1=0.29326iou=0.16177loss=0.99997.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 170: 'f1' reached 0.31373 (best 0.31373), saving model to './mlruns/124960261813571015/5801385d6f0245a7b11b53c65fbc3e14/checkpoints/f1_epoch=1f1=0.31373iou=0.16703loss=0.99110.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 255: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 340: 'f1' reached 0.32523 (best 0.32523), saving model to './mlruns/124960261813571015/5801385d6f0245a7b11b53c65fbc3e14/checkpoints/f1_epoch=3f1=0.32523iou=0.17059loss=0.98505.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 425: 'f1' reached 0.36036 (best 0.36036), saving model to './mlruns/124960261813571015/5801385d6f0245a7b11b53c65fbc3e14/checkpoints/f1_epoch=4f1=0.36036iou=0.18346loss=0.98052.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 510: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 595: 'f1' reached 0.42306 (best 0.42306), saving model to './mlruns/124960261813571015/5801385d6f0245a7b11b53c65fbc3e14/checkpoints/f1_epoch=6f1=0.42306iou=0.21762loss=0.97899.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 680: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 765: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 850: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 935: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 1020: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 1105: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 1190: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 1275: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, global step 1360: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, global step 1445: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, global step 1530: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18, global step 1615: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 1700: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20, global step 1785: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21, global step 1870: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22, global step 1955: 'f1' reached 0.42945 (best 0.42945), saving model to './mlruns/124960261813571015/5801385d6f0245a7b11b53c65fbc3e14/checkpoints/f1_epoch=22f1=0.42945iou=0.20948loss=0.97864.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23, global step 2040: 'f1' reached 0.44323 (best 0.44323), saving model to './mlruns/124960261813571015/5801385d6f0245a7b11b53c65fbc3e14/checkpoints/f1_epoch=23f1=0.44323iou=0.21721loss=0.97230.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24, global step 2125: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25, global step 2210: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26, global step 2295: 'f1' reached 0.44530 (best 0.44530), saving model to './mlruns/124960261813571015/5801385d6f0245a7b11b53c65fbc3e14/checkpoints/f1_epoch=26f1=0.44530iou=0.20638loss=0.98119.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27, global step 2380: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28, global step 2465: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29, global step 2550: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30, global step 2635: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31, global step 2720: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32, global step 2805: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33, global step 2890: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34, global step 2975: 'f1' reached 0.47219 (best 0.47219), saving model to './mlruns/124960261813571015/5801385d6f0245a7b11b53c65fbc3e14/checkpoints/f1_epoch=34f1=0.47219iou=0.22780loss=0.97680.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35, global step 3060: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36, global step 3145: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37, global step 3230: 'f1' reached 0.48220 (best 0.48220), saving model to './mlruns/124960261813571015/5801385d6f0245a7b11b53c65fbc3e14/checkpoints/f1_epoch=37f1=0.48220iou=0.24055loss=0.96727.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38, global step 3315: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39, global step 3400: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40, global step 3485: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41, global step 3570: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42, global step 3655: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43, global step 3740: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44, global step 3825: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45, global step 3910: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46, global step 3995: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47, global step 4080: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48, global step 4165: 'f1' reached 0.48839 (best 0.48839), saving model to './mlruns/124960261813571015/5801385d6f0245a7b11b53c65fbc3e14/checkpoints/f1_epoch=48f1=0.48839iou=0.22835loss=0.96364.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49, global step 4250: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50, global step 4335: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51, global step 4420: 'f1' reached 0.48857 (best 0.48857), saving model to './mlruns/124960261813571015/5801385d6f0245a7b11b53c65fbc3e14/checkpoints/f1_epoch=51f1=0.48857iou=0.24307loss=0.97100.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52, global step 4505: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53, global step 4590: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54, global step 4675: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55, global step 4760: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56, global step 4845: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57, global step 4930: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58, global step 5015: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59, global step 5100: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60, global step 5185: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61, global step 5270: 'f1' reached 0.49691 (best 0.49691), saving model to './mlruns/124960261813571015/5801385d6f0245a7b11b53c65fbc3e14/checkpoints/f1_epoch=61f1=0.49691iou=0.24135loss=0.97519.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62, global step 5355: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63, global step 5440: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64, global step 5525: 'f1' reached 0.49949 (best 0.49949), saving model to './mlruns/124960261813571015/5801385d6f0245a7b11b53c65fbc3e14/checkpoints/f1_epoch=64f1=0.49949iou=0.23804loss=0.96841.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65, global step 5610: 'f1' reached 0.50024 (best 0.50024), saving model to './mlruns/124960261813571015/5801385d6f0245a7b11b53c65fbc3e14/checkpoints/f1_epoch=65f1=0.50024iou=0.23871loss=0.96088.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66, global step 5695: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67, global step 5780: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68, global step 5865: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69, global step 5950: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70, global step 6035: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71, global step 6120: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72, global step 6205: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73, global step 6290: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74, global step 6375: 'f1' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75, global step 6460: 'f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/tomek/inz/inz/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:54: Detected \n",
       "KeyboardInterrupt, attempting graceful shutdown...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/tomek/inz/inz/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:54: Detected \n",
       "KeyboardInterrupt, attempting graceful shutdown...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/12 13:59:25 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpj98eeqnh/model/data, flavor: pytorch). Fall back to return ['torch==2.2.2', 'cloudpickle==3.0.0']. Set logging level to DEBUG to see the full traceback. \n"
     ]
    }
   ],
   "source": [
    "mlflow.pytorch.autolog()\n",
    "\n",
    "\n",
    "f1_checkpoint_callback = ModelCheckpoint(\n",
    "    save_top_k=1, verbose=True, monitor=\"f1\", mode=\"max\", filename=\"f1_{epoch}{f1:.5f}{iou:.5f}{loss:.5f}\"\n",
    ")\n",
    "\n",
    "# iou_checkpoint_callback = ModelCheckpoint(\n",
    "#     save_top_k=1, verbose=True, monitor=\"iou\", mode=\"max\", filename=\"iou_{epoch}{f1:.5f}{iou:.5f}{loss:.5f}\"\n",
    "# )\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=500,\n",
    "    callbacks=[\n",
    "        RichProgressBar(),\n",
    "        f1_checkpoint_callback,\n",
    "        # iou_checkpoint_callback,\n",
    "    ],\n",
    "    logger=MLFlowLogger(experiment_name=\"basic_siamese\"),\n",
    "    precision=\"bf16\",\n",
    ")\n",
    "trainer.fit(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
