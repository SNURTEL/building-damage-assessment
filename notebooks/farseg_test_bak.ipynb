{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from simplecv.module import fpn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import dotenv\n",
    "import pytorch_lightning as pl\n",
    "from pathlib import Path\n",
    "from typing import Any, Callable\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "import torchmetrics.classification\n",
    "import torchmetrics.segmentation\n",
    "from torch import Tensor\n",
    "\n",
    "import dotenv\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, RichProgressBar\n",
    "\n",
    "from inz.data.data_module import XBDDataModule\n",
    "from inz.data.event import Event, Tier3\n",
    "from inz.models.baseline_module import BaselineModule\n",
    "from inz.util import get_loc_cls_weights, get_wandb_logger, show_masks_comparison\n",
    "from inz.xview2_strong_baseline.legacy.losses import ComboLoss\n",
    "from inz.xview2_strong_baseline.legacy.zoo.models import Res34_Unet_Double\n",
    "\n",
    "sys.path.append(\"inz/farseg\")\n",
    "\n",
    "from inz.farseg.module.farseg import FarSeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning_fabric.utilities.seed:Seed set to 123\n"
     ]
    }
   ],
   "source": [
    "dotenv.load_dotenv()\n",
    "RANDOM_SEED = 123\n",
    "pl.seed_everything(RANDOM_SEED)\n",
    "device = torch.device(\"cuda\")\n",
    "torch.set_float32_matmul_precision(\"high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 train batches, 3 val batches\n"
     ]
    }
   ],
   "source": [
    "dm = XBDDataModule(\n",
    "    path=Path(\"data/xBD_processed_noresize\"),\n",
    "    drop_unclassified_channel=True,\n",
    "    events={\n",
    "        Tier3: [\n",
    "            Event.joplin_tornado,\n",
    "        ],\n",
    "    },\n",
    "    val_fraction=0.15,\n",
    "    test_fraction=0.0,\n",
    "    train_batch_size=8,\n",
    "    val_batch_size=8,\n",
    "    test_batch_size=8,\n",
    ")\n",
    "dm.prepare_data()\n",
    "dm.setup(\"fit\")\n",
    "\n",
    "print(f\"{len(dm.train_dataloader())} train batches, {len(dm.val_dataloader())} val batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    resnet_encoder=dict(\n",
    "        resnet_type=\"resnet50\",\n",
    "        include_conv5=True,\n",
    "        batchnorm_trainable=True,\n",
    "        pretrained=True,\n",
    "        freeze_at=0,\n",
    "        # 8, 16 or 32\n",
    "        output_stride=32,\n",
    "        with_cp=(False, False, False, False),\n",
    "        stem3_3x3=False,\n",
    "    ),\n",
    "    fpn=dict(\n",
    "        in_channels_list=(256, 512, 1024, 2048),\n",
    "        out_channels=256,\n",
    "        conv_block=fpn.default_conv_block,\n",
    "        top_blocks=None,\n",
    "    ),\n",
    "    scene_relation=dict(\n",
    "        in_channels=2048,\n",
    "        channel_list=(256, 256, 256, 256),\n",
    "        out_channels=256,\n",
    "        scale_aware_proj=True,\n",
    "    ),\n",
    "    decoder=dict(\n",
    "        in_channels=256,\n",
    "        out_channels=128,\n",
    "        in_feat_output_strides=(4, 8, 16, 32),\n",
    "        out_feat_output_stride=4,\n",
    "        norm_fn=nn.BatchNorm2d,\n",
    "        num_groups_gn=None,\n",
    "    ),\n",
    "    num_classes=5,\n",
    "    loss=dict(\n",
    "        cls_weight=1.0,\n",
    "        ignore_index=255,\n",
    "    ),\n",
    "    annealing_softmax_focalloss=dict(gamma=2.0, max_step=10000, annealing_type=\"cosine\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleBranchFarSeg(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        farseg_config: dict,\n",
    "        n_classes: int\n",
    "    ):\n",
    "        super(DoubleBranchFarSeg, self).__init__()\n",
    "        self.farseg_config = farseg_config\n",
    "        self.n_classes = n_classes\n",
    "        self.module = FarSeg(config=farseg_config)\n",
    "        self.outconv = nn.Conv2d(farseg_config[\"decoder\"][\"out_channels\"] * 2, n_classes, 1)\n",
    "\n",
    "    def _module_forward(self, x, module):\n",
    "        feat_list = module.en(x)\n",
    "        fpn_feat_list = module.fpn(feat_list)\n",
    "        if 'scene_relation' in module.config:\n",
    "            c5 = feat_list[-1]\n",
    "            c6 = module.gap(c5)\n",
    "            refined_fpn_feat_list = module.sr(c6, fpn_feat_list)\n",
    "        else:\n",
    "            refined_fpn_feat_list = fpn_feat_list\n",
    "\n",
    "        return module.decoder(refined_fpn_feat_list)\n",
    "\n",
    "    def forward(self, x1: torch.Tensor, x2: torch.Tensor) -> torch.Tensor:\n",
    "        x1 = self._module_forward(x1, self.module)\n",
    "        x2 = self._module_forward(x2, self.module)\n",
    "        return self.outconv.forward(torch.cat([x1, x2], dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simplecv.util.logger:ResNetEncoder: pretrained = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene_relation: on\n",
      "loss type: cosine\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DoubleBranchFarSeg(\n",
       "  (module): FarSeg(\n",
       "    (en): ResNetEncoder(\n",
       "      (resnet): ResNet(\n",
       "        (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        (layer1): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (4): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (5): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (fpn): FPN(\n",
       "      (fpn_inner1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (fpn_layer1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (fpn_inner2): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (fpn_layer2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (fpn_inner3): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (fpn_layer3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (fpn_inner4): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (fpn_layer4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (decoder): AssymetricDecoder(\n",
       "      (blocks): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Identity()\n",
       "          )\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): UpsamplingBilinear2d(scale_factor=2.0, mode='bilinear')\n",
       "          )\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): UpsamplingBilinear2d(scale_factor=2.0, mode='bilinear')\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): UpsamplingBilinear2d(scale_factor=2.0, mode='bilinear')\n",
       "          )\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): UpsamplingBilinear2d(scale_factor=2.0, mode='bilinear')\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): UpsamplingBilinear2d(scale_factor=2.0, mode='bilinear')\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): UpsamplingBilinear2d(scale_factor=2.0, mode='bilinear')\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (cls_pred_conv): Conv2d(128, 5, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (upsample4x_op): UpsamplingBilinear2d(scale_factor=4.0, mode='bilinear')\n",
       "    (gap): AdaptiveAvgPool2d(output_size=1)\n",
       "    (sr): SceneRelation(\n",
       "      (scene_encoder): ModuleList(\n",
       "        (0-3): 4 x Sequential(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (content_encoders): ModuleList(\n",
       "        (0-3): 4 x Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (feature_reencoders): ModuleList(\n",
       "        (0-3): 4 x Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (normalizer): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (outconv): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module = DoubleBranchFarSeg(farseg_config=config, n_classes=5).to(device)\n",
    "module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 2.3378e-01,  1.3187e-01, -8.7459e-03,  ..., -3.3284e-02,\n",
       "           -1.6368e-02,  1.4929e-01],\n",
       "          [ 1.6156e-01,  1.8875e-01,  1.4566e-01,  ...,  3.7550e-02,\n",
       "            3.4384e-02,  1.2225e-01],\n",
       "          [ 9.2675e-02,  1.4514e-01,  1.9306e-01,  ..., -4.4589e-02,\n",
       "            3.8915e-03,  7.1288e-02],\n",
       "          ...,\n",
       "          [ 1.0555e-01,  1.2524e-04, -5.6513e-02,  ...,  2.1224e-01,\n",
       "            1.1614e-01,  1.7065e-01],\n",
       "          [ 9.3180e-02,  1.0335e-01,  3.2186e-02,  ...,  1.3751e-01,\n",
       "            5.7803e-02,  2.2310e-01],\n",
       "          [ 6.4131e-02,  8.1607e-02,  3.8296e-02,  ...,  7.8346e-03,\n",
       "            9.1136e-02,  1.1579e-01]],\n",
       "\n",
       "         [[ 1.3928e-01,  1.4977e-01,  1.9038e-01,  ..., -1.1426e-01,\n",
       "           -2.0719e-01, -7.7461e-02],\n",
       "          [ 1.0370e-01,  6.4732e-02,  1.1475e-01,  ..., -6.8705e-02,\n",
       "           -1.5121e-01, -2.4426e-02],\n",
       "          [ 5.3508e-02,  5.5013e-02,  4.7841e-02,  ..., -9.4921e-02,\n",
       "           -8.4437e-02, -2.2836e-01],\n",
       "          ...,\n",
       "          [-5.4838e-02, -7.8909e-02, -7.4530e-02,  ..., -7.1475e-02,\n",
       "           -2.0094e-02,  1.4754e-01],\n",
       "          [-4.3164e-02, -3.3737e-02, -6.0087e-02,  ..., -2.7977e-02,\n",
       "            2.9319e-02,  1.5918e-01],\n",
       "          [-5.6879e-02, -5.6364e-02, -5.8120e-02,  ..., -1.0756e-01,\n",
       "           -5.1282e-02,  4.2265e-02]],\n",
       "\n",
       "         [[ 9.3564e-02,  1.2978e-01,  1.9744e-01,  ...,  1.7579e-02,\n",
       "            2.2124e-01,  2.6384e-01],\n",
       "          [ 1.8886e-01,  1.8915e-01,  2.7101e-01,  ...,  1.2260e-01,\n",
       "            3.7287e-01,  2.9423e-01],\n",
       "          [ 2.1080e-01,  2.5882e-01,  3.0507e-01,  ...,  1.0073e-01,\n",
       "            3.3649e-01,  3.7817e-01],\n",
       "          ...,\n",
       "          [ 2.7195e-01,  2.4198e-01,  1.3457e-01,  ...,  1.3631e-01,\n",
       "            2.4286e-01,  2.0972e-01],\n",
       "          [ 2.3031e-01,  2.3961e-01,  1.6528e-01,  ...,  2.1413e-01,\n",
       "            1.4080e-01,  2.3506e-01],\n",
       "          [ 2.1216e-01,  1.3966e-01,  1.4254e-01,  ...,  6.5858e-02,\n",
       "            5.8114e-02,  1.3004e-01]],\n",
       "\n",
       "         [[ 5.6765e-02,  1.7461e-02, -1.2627e-01,  ..., -2.3843e-02,\n",
       "           -6.4274e-02, -2.4310e-02],\n",
       "          [ 6.8138e-02,  7.9149e-02,  8.7323e-02,  ..., -2.6433e-02,\n",
       "           -5.5474e-02,  9.8913e-02],\n",
       "          [ 6.8787e-02,  1.4659e-01,  2.0942e-01,  ..., -6.3151e-02,\n",
       "           -5.6896e-02,  1.9113e-01],\n",
       "          ...,\n",
       "          [ 9.8530e-02,  3.6327e-02, -2.8607e-02,  ...,  1.0938e-01,\n",
       "            1.9388e-01,  1.0969e-01],\n",
       "          [ 9.8591e-02, -2.0494e-02, -3.7284e-02,  ...,  4.5761e-02,\n",
       "            1.2782e-01,  7.4740e-02],\n",
       "          [-4.9522e-03, -4.1587e-02, -6.0382e-02,  ..., -3.5419e-02,\n",
       "           -1.8498e-02,  4.8443e-02]],\n",
       "\n",
       "         [[-1.5187e-01, -1.3984e-01, -1.7935e-01,  ..., -2.7239e-01,\n",
       "           -3.5908e-01, -8.9502e-02],\n",
       "          [-5.8781e-02, -9.4147e-02, -7.9639e-02,  ..., -3.0100e-01,\n",
       "           -3.6604e-01, -1.9619e-01],\n",
       "          [-2.3442e-02, -2.7140e-02, -5.5271e-02,  ..., -2.8979e-01,\n",
       "           -3.6192e-01, -3.0220e-01],\n",
       "          ...,\n",
       "          [-1.2060e-01, -1.7316e-02,  8.0577e-02,  ..., -1.2352e-01,\n",
       "           -1.3620e-01,  2.3725e-02],\n",
       "          [-1.2305e-01, -7.2191e-02,  8.0544e-02,  ..., -1.0823e-01,\n",
       "           -1.1664e-01,  2.4092e-02],\n",
       "          [-1.0398e-01, -5.9236e-02,  3.1971e-02,  ..., -8.5147e-02,\n",
       "           -8.0514e-02, -3.3129e-03]]],\n",
       "\n",
       "\n",
       "        [[[ 6.0617e-02, -2.9461e-02,  1.5859e-02,  ...,  1.4380e-02,\n",
       "           -1.8285e-02,  7.5052e-02],\n",
       "          [-1.1217e-02,  2.1972e-02,  9.1038e-02,  ..., -5.1431e-02,\n",
       "           -3.6686e-02,  7.2725e-02],\n",
       "          [-4.1006e-02, -5.2113e-02,  9.8454e-02,  ..., -8.1139e-02,\n",
       "           -1.0458e-01,  1.4876e-02],\n",
       "          ...,\n",
       "          [ 1.6013e-01,  3.1775e-01,  2.4797e-01,  ...,  3.2384e-02,\n",
       "            1.5798e-01, -2.5368e-02],\n",
       "          [ 3.8651e-02,  1.5026e-01,  2.2900e-01,  ...,  2.3321e-02,\n",
       "            2.1194e-01,  1.6815e-01],\n",
       "          [ 1.2940e-01,  1.4225e-01,  1.1647e-01,  ...,  2.9131e-01,\n",
       "            2.3334e-01,  2.1381e-01]],\n",
       "\n",
       "         [[ 2.0870e-01,  1.8352e-01,  4.1371e-03,  ...,  2.7888e-02,\n",
       "            5.7615e-02,  1.0484e-01],\n",
       "          [ 1.4495e-01,  1.0745e-01,  1.2393e-01,  ..., -1.1021e-02,\n",
       "           -1.8965e-02,  1.2246e-01],\n",
       "          [ 1.6568e-02,  1.0568e-01,  6.8631e-02,  ..., -1.1121e-02,\n",
       "            5.6796e-02,  7.4605e-02],\n",
       "          ...,\n",
       "          [ 1.4975e-02,  1.2097e-01,  1.3181e-01,  ..., -1.8972e-01,\n",
       "           -1.7084e-01, -2.0270e-01],\n",
       "          [ 1.4516e-01,  1.7010e-01,  1.9125e-01,  ..., -1.8846e-01,\n",
       "           -1.9509e-01, -1.0326e-01],\n",
       "          [ 1.3992e-01,  1.4284e-02, -5.1482e-02,  ..., -1.0191e-01,\n",
       "           -9.7436e-02, -2.1719e-01]],\n",
       "\n",
       "         [[ 1.8447e-01,  1.9482e-01,  7.1672e-02,  ...,  2.6090e-01,\n",
       "            2.7852e-01,  3.1037e-01],\n",
       "          [ 2.6207e-01,  3.2645e-01,  2.1776e-01,  ...,  2.2356e-01,\n",
       "            2.9163e-01,  2.9624e-01],\n",
       "          [ 1.5204e-01,  3.2509e-01,  1.0680e-01,  ...,  2.1187e-01,\n",
       "            3.1808e-01,  3.0932e-01],\n",
       "          ...,\n",
       "          [ 1.8508e-01,  1.1278e-01,  8.1855e-02,  ...,  2.3380e-01,\n",
       "            2.8307e-01,  6.0105e-02],\n",
       "          [ 1.9816e-01,  1.4118e-01,  1.5529e-01,  ...,  1.3822e-01,\n",
       "            1.1249e-01,  1.8594e-02],\n",
       "          [ 1.5877e-01,  1.3904e-01,  1.6149e-01,  ...,  7.6050e-02,\n",
       "            9.2269e-02,  1.4550e-01]],\n",
       "\n",
       "         [[ 1.4577e-01,  3.7184e-02,  1.6581e-02,  ...,  7.2333e-02,\n",
       "            3.6305e-02,  2.5325e-02],\n",
       "          [ 4.5208e-02, -5.4723e-02, -5.0774e-02,  ...,  8.9087e-02,\n",
       "            1.3874e-03, -1.5474e-02],\n",
       "          [-1.8417e-02, -1.7631e-02, -1.0594e-01,  ...,  7.5140e-02,\n",
       "            3.9751e-02,  1.1484e-02],\n",
       "          ...,\n",
       "          [-4.4858e-03, -8.1551e-03,  3.9989e-02,  ...,  2.7927e-01,\n",
       "            2.8643e-01,  9.9159e-02],\n",
       "          [-2.2324e-02, -4.1794e-03, -1.3109e-02,  ...,  2.0124e-01,\n",
       "            3.5689e-01,  2.6600e-01],\n",
       "          [ 3.0051e-02, -6.8769e-02, -1.4850e-01,  ...,  1.5273e-01,\n",
       "            3.1949e-01,  2.6877e-01]],\n",
       "\n",
       "         [[-3.2457e-01, -3.1884e-01, -2.9924e-01,  ..., -2.6159e-02,\n",
       "           -8.9643e-02,  2.2449e-02],\n",
       "          [-3.1248e-01, -3.6736e-01, -2.0706e-01,  ..., -1.4252e-01,\n",
       "           -9.2389e-02, -5.7716e-02],\n",
       "          [-2.9479e-01, -4.1254e-01, -4.9059e-01,  ..., -1.7423e-01,\n",
       "           -1.5697e-01, -1.3447e-01],\n",
       "          ...,\n",
       "          [-1.4892e-01, -1.2272e-01, -2.3067e-01,  ...,  2.0621e-01,\n",
       "            1.4074e-01,  2.6397e-01],\n",
       "          [-1.2072e-01, -1.7008e-01, -1.9065e-01,  ...,  1.3456e-01,\n",
       "            3.5057e-02,  2.2265e-01],\n",
       "          [-1.6237e-01, -2.1048e-01, -1.3687e-01,  ...,  2.1387e-01,\n",
       "            1.3825e-01,  1.8860e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.2445e-01,  3.1932e-02, -8.9350e-02,  ...,  9.0720e-02,\n",
       "            1.3132e-02,  1.7878e-01],\n",
       "          [ 1.2146e-01, -2.6747e-02, -6.3387e-02,  ...,  4.4143e-02,\n",
       "           -7.3615e-02,  2.3737e-01],\n",
       "          [ 1.4751e-01,  6.9573e-02, -2.1951e-03,  ...,  3.0817e-01,\n",
       "            3.5490e-01,  3.8181e-01],\n",
       "          ...,\n",
       "          [ 8.8700e-02,  1.2660e-01,  9.6584e-02,  ...,  2.5427e-02,\n",
       "           -3.3903e-02,  5.3443e-03],\n",
       "          [ 5.2931e-02,  1.3761e-01,  3.7237e-02,  ...,  6.1915e-02,\n",
       "            1.4528e-04,  9.4582e-02],\n",
       "          [-1.4121e-04,  1.1153e-01,  1.4009e-01,  ...,  9.3682e-02,\n",
       "            1.1927e-01,  1.0992e-01]],\n",
       "\n",
       "         [[-5.3553e-02,  4.7797e-03,  3.5902e-02,  ..., -1.8257e-01,\n",
       "           -2.5611e-01, -1.0754e-01],\n",
       "          [-1.1551e-01, -1.0188e-01, -6.6746e-02,  ..., -1.2930e-01,\n",
       "           -1.2465e-01, -9.7156e-02],\n",
       "          [-2.0307e-01, -1.4568e-01, -1.5107e-01,  ...,  4.3769e-02,\n",
       "           -1.2332e-01, -7.7973e-02],\n",
       "          ...,\n",
       "          [ 1.5903e-01,  1.8220e-01,  7.0812e-02,  ..., -4.4664e-02,\n",
       "           -4.1840e-02,  3.3439e-02],\n",
       "          [ 1.6398e-01,  1.6210e-01,  9.0986e-02,  ...,  1.1296e-02,\n",
       "            8.3372e-03,  1.8987e-02],\n",
       "          [ 8.8418e-02,  7.3634e-02,  3.7271e-02,  ...,  1.9451e-03,\n",
       "            4.9305e-02,  7.6954e-03]],\n",
       "\n",
       "         [[ 5.8259e-02,  1.4503e-01,  1.7334e-01,  ..., -2.0501e-02,\n",
       "            4.7611e-02,  8.1233e-02],\n",
       "          [ 1.9728e-01,  2.2139e-01,  2.3615e-01,  ...,  2.6099e-01,\n",
       "            1.4706e-01, -3.7638e-02],\n",
       "          [ 2.4874e-01,  1.4239e-01,  1.4066e-01,  ...,  3.3685e-01,\n",
       "            1.8582e-01, -3.5923e-02],\n",
       "          ...,\n",
       "          [ 2.9542e-01,  3.7890e-01,  4.3798e-01,  ..., -8.7535e-02,\n",
       "            1.1064e-01,  1.6916e-01],\n",
       "          [ 2.6827e-01,  2.7130e-01,  3.8159e-01,  ..., -1.0010e-01,\n",
       "            4.6990e-02,  9.6112e-02],\n",
       "          [ 2.2766e-01,  1.9474e-01,  1.7745e-01,  ..., -7.7621e-02,\n",
       "            9.7624e-03,  1.4732e-01]],\n",
       "\n",
       "         [[ 6.4160e-02,  2.8247e-02, -1.3022e-01,  ...,  1.2213e-01,\n",
       "            1.1219e-01, -2.2157e-02],\n",
       "          [ 1.3812e-01,  3.0191e-02, -1.0674e-01,  ..., -4.1269e-02,\n",
       "           -2.2522e-02, -2.5274e-02],\n",
       "          [ 9.2561e-02, -4.7447e-02, -1.4434e-01,  ..., -6.1006e-02,\n",
       "           -3.9149e-02, -5.2371e-02],\n",
       "          ...,\n",
       "          [ 2.5215e-01,  6.7720e-02, -3.9360e-02,  ..., -4.2309e-02,\n",
       "           -1.1888e-02, -7.8751e-02],\n",
       "          [ 2.2860e-01,  2.7222e-02,  2.5957e-02,  ..., -8.9651e-03,\n",
       "           -3.0578e-02, -6.5915e-02],\n",
       "          [ 1.5447e-01,  1.4776e-01,  1.1810e-01,  ..., -1.5197e-01,\n",
       "           -1.5834e-01, -1.2718e-01]],\n",
       "\n",
       "         [[-7.0186e-02, -6.7951e-02, -1.3361e-01,  ..., -1.1352e-01,\n",
       "           -2.1306e-01, -1.4755e-01],\n",
       "          [-2.6562e-02, -2.7401e-03, -5.2246e-02,  ..., -1.5552e-01,\n",
       "           -1.8955e-01,  1.4902e-02],\n",
       "          [-3.9951e-02, -3.1346e-02, -6.3766e-02,  ..., -3.8424e-01,\n",
       "           -3.7063e-01, -2.7377e-01],\n",
       "          ...,\n",
       "          [ 1.5126e-01,  1.0181e-01,  8.1802e-02,  ..., -1.0011e-01,\n",
       "           -1.6665e-01, -7.9679e-02],\n",
       "          [ 6.9343e-02,  1.7806e-02,  4.4368e-02,  ..., -4.6981e-02,\n",
       "           -1.5197e-01, -5.6552e-02],\n",
       "          [-7.3462e-02, -3.9924e-04,  5.1981e-02,  ..., -3.2790e-02,\n",
       "           -5.9349e-02, -5.9232e-02]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 2.0596e-01,  1.0873e-01,  5.9898e-02,  ..., -1.4613e-01,\n",
       "           -2.0990e-02,  5.0517e-02],\n",
       "          [ 1.5943e-01,  4.4750e-02,  9.6120e-03,  ..., -1.3934e-01,\n",
       "           -3.6388e-02,  2.4406e-02],\n",
       "          [ 1.1551e-01, -2.7483e-03, -1.2135e-02,  ..., -1.3511e-01,\n",
       "           -5.2265e-02,  3.4510e-02],\n",
       "          ...,\n",
       "          [ 1.8141e-02,  2.9882e-02, -4.3047e-02,  ...,  1.8340e-02,\n",
       "            3.4367e-02,  1.2077e-01],\n",
       "          [-2.3723e-03,  3.2132e-02, -2.9416e-02,  ..., -3.4712e-02,\n",
       "            3.2774e-02,  1.5695e-01],\n",
       "          [ 7.1546e-02, -9.5888e-03,  2.7066e-03,  ..., -5.4638e-03,\n",
       "           -1.0737e-03,  7.5907e-02]],\n",
       "\n",
       "         [[ 2.4580e-02,  6.1048e-02,  1.5605e-01,  ...,  3.1238e-02,\n",
       "           -3.1763e-02, -2.7876e-02],\n",
       "          [-3.5901e-02, -9.5453e-03,  1.1539e-01,  ...,  6.4369e-02,\n",
       "            8.4459e-02, -1.4983e-02],\n",
       "          [-8.9268e-02, -6.4709e-03,  2.0806e-02,  ...,  1.2793e-01,\n",
       "            1.2360e-01,  3.4713e-02],\n",
       "          ...,\n",
       "          [-3.6113e-02,  4.3259e-02,  7.7102e-02,  ..., -1.2383e-01,\n",
       "           -4.7919e-02, -8.4570e-02],\n",
       "          [-6.4834e-02, -6.7808e-03,  5.3350e-02,  ..., -1.0332e-01,\n",
       "           -9.7422e-03, -5.9968e-02],\n",
       "          [-5.6909e-02, -9.9237e-02, -5.0379e-02,  ..., -1.3485e-01,\n",
       "           -9.9480e-02, -1.2592e-01]],\n",
       "\n",
       "         [[ 2.2730e-02,  7.0508e-02,  8.3457e-02,  ..., -4.1390e-02,\n",
       "            1.0255e-01,  1.6752e-01],\n",
       "          [ 6.5440e-02,  1.2986e-01,  1.5666e-01,  ...,  8.1351e-02,\n",
       "            2.1288e-01,  2.4894e-01],\n",
       "          [ 9.1167e-02,  1.8179e-01,  2.0444e-01,  ...,  1.4873e-01,\n",
       "            2.6609e-01,  3.2240e-01],\n",
       "          ...,\n",
       "          [ 3.7060e-02,  1.0028e-01,  8.8550e-02,  ...,  4.7220e-02,\n",
       "            8.3119e-02,  2.9476e-02],\n",
       "          [ 7.7695e-02,  5.6038e-02,  1.3477e-01,  ...,  1.2704e-01,\n",
       "            1.4239e-01,  9.3767e-02],\n",
       "          [ 9.3941e-02,  8.1384e-02,  8.4955e-02,  ...,  1.5078e-01,\n",
       "            1.7335e-01,  1.0277e-01]],\n",
       "\n",
       "         [[ 1.2131e-01, -7.9496e-03, -1.8138e-01,  ..., -1.6680e-01,\n",
       "           -1.3057e-01, -9.8984e-02],\n",
       "          [ 8.3130e-02, -8.4219e-03, -1.7054e-01,  ..., -2.0469e-01,\n",
       "           -2.2396e-01, -1.1323e-01],\n",
       "          [ 3.5863e-02, -1.5019e-02, -1.1033e-01,  ..., -1.5519e-01,\n",
       "           -1.8690e-01, -1.4424e-01],\n",
       "          ...,\n",
       "          [-7.1519e-02, -5.4261e-02, -1.7990e-01,  ..., -1.3046e-01,\n",
       "           -8.7524e-02,  3.6980e-02],\n",
       "          [-1.8127e-02, -2.7616e-02, -1.0589e-01,  ..., -1.3637e-01,\n",
       "           -1.1706e-01,  1.0365e-02],\n",
       "          [-1.8711e-02, -1.3833e-01, -1.5466e-01,  ..., -1.1270e-01,\n",
       "           -1.1833e-01, -2.6912e-02]],\n",
       "\n",
       "         [[-3.5449e-02, -1.2984e-01, -2.0567e-01,  ...,  7.5408e-05,\n",
       "            2.9170e-02,  2.1334e-01],\n",
       "          [ 4.3547e-02,  5.6619e-03, -1.2250e-02,  ...,  9.6678e-02,\n",
       "            7.3564e-02,  1.0731e-01],\n",
       "          [ 1.4777e-01,  1.6664e-01,  1.3152e-01,  ...,  2.1180e-01,\n",
       "            9.5036e-02,  9.0925e-02],\n",
       "          ...,\n",
       "          [-5.4162e-02,  1.9395e-03, -1.6463e-01,  ..., -1.8744e-01,\n",
       "           -2.1287e-01, -2.1417e-01],\n",
       "          [-4.6129e-02, -1.6547e-02, -9.9225e-02,  ..., -3.2769e-01,\n",
       "           -3.1212e-01, -2.1657e-01],\n",
       "          [-4.4894e-02, -4.0281e-02, -1.3940e-01,  ..., -1.7097e-01,\n",
       "           -1.9617e-01, -1.9398e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.8947e-01,  6.7425e-02, -2.1817e-02,  ..., -4.5543e-02,\n",
       "            6.8235e-02,  1.6237e-01],\n",
       "          [ 1.4263e-01,  7.8578e-02,  6.1189e-02,  ...,  5.4137e-02,\n",
       "            1.2636e-01,  1.2264e-01],\n",
       "          [ 3.6308e-02,  6.0075e-02,  8.9957e-02,  ...,  8.2814e-02,\n",
       "            1.1883e-01,  1.9623e-01],\n",
       "          ...,\n",
       "          [ 8.3209e-02,  1.5443e-02, -3.3346e-02,  ...,  1.9743e-02,\n",
       "            3.9126e-03,  2.4398e-02],\n",
       "          [ 5.7492e-02,  8.0119e-03, -7.8709e-02,  ..., -3.6890e-03,\n",
       "            3.1810e-02,  2.0742e-02],\n",
       "          [ 7.4568e-03,  1.9593e-02, -2.9838e-02,  ...,  2.7992e-02,\n",
       "            1.2381e-01,  1.4742e-01]],\n",
       "\n",
       "         [[ 7.2802e-02,  1.4202e-01,  2.7732e-01,  ..., -1.1193e-01,\n",
       "           -2.2453e-01, -2.1002e-02],\n",
       "          [ 1.1179e-02,  6.9196e-02,  1.7561e-01,  ..., -1.3361e-01,\n",
       "           -1.6053e-01, -8.9742e-03],\n",
       "          [-5.6841e-02,  4.1768e-02,  1.1821e-01,  ..., -2.6986e-01,\n",
       "           -2.1858e-01, -1.7483e-01],\n",
       "          ...,\n",
       "          [-1.1311e-01, -1.4505e-01, -9.8742e-02,  ..., -5.4518e-02,\n",
       "           -7.3380e-02, -1.0815e-04],\n",
       "          [-5.6576e-02, -2.7681e-02, -4.7790e-02,  ..., -1.6253e-01,\n",
       "           -1.4356e-02,  3.8809e-02],\n",
       "          [-3.3423e-02, -6.5016e-02, -3.3300e-02,  ..., -1.6613e-01,\n",
       "           -9.5733e-02, -1.2906e-01]],\n",
       "\n",
       "         [[ 1.3750e-02,  3.5812e-02,  9.8467e-02,  ...,  3.5975e-01,\n",
       "            3.5105e-01,  3.5010e-01],\n",
       "          [ 4.0297e-02,  5.0690e-02,  7.2471e-02,  ...,  4.0078e-01,\n",
       "            4.6476e-01,  4.0343e-01],\n",
       "          [ 5.5406e-02,  2.1471e-02,  1.5612e-02,  ...,  2.2571e-01,\n",
       "            3.9882e-01,  3.3698e-01],\n",
       "          ...,\n",
       "          [ 7.8615e-02,  1.2599e-01,  1.2900e-01,  ...,  5.3158e-02,\n",
       "            1.7522e-01,  1.6951e-01],\n",
       "          [ 1.4666e-01,  1.6626e-01,  1.8300e-01,  ...,  5.6436e-02,\n",
       "            7.8327e-02,  1.7210e-01],\n",
       "          [ 2.1393e-01,  3.3438e-02,  4.1668e-03,  ...,  9.0109e-02,\n",
       "            1.8905e-01,  2.2970e-01]],\n",
       "\n",
       "         [[-1.3554e-02, -1.1048e-01, -2.0888e-01,  ...,  1.8988e-01,\n",
       "            8.8317e-02, -8.0514e-02],\n",
       "          [-7.1389e-02, -1.4902e-01, -2.5981e-01,  ...,  1.2483e-01,\n",
       "            1.4551e-01,  5.2090e-02],\n",
       "          [-1.4063e-01, -2.4225e-01, -3.4402e-01,  ...,  1.1339e-01,\n",
       "            2.3912e-01,  5.8447e-02],\n",
       "          ...,\n",
       "          [ 1.9078e-01,  1.2884e-01,  2.5174e-02,  ..., -1.1643e-01,\n",
       "           -5.5509e-02, -5.9361e-02],\n",
       "          [ 1.3831e-01,  8.5856e-02,  6.8223e-02,  ..., -6.4462e-02,\n",
       "           -6.7614e-02, -3.8470e-02],\n",
       "          [ 8.5767e-02,  1.7831e-02, -5.4535e-02,  ..., -6.8895e-04,\n",
       "           -7.0529e-02,  4.5394e-02]],\n",
       "\n",
       "         [[ 6.1669e-02,  5.5456e-02,  1.8018e-02,  ..., -2.8030e-01,\n",
       "           -2.6457e-01, -2.6416e-01],\n",
       "          [ 1.8158e-01,  8.1921e-02, -5.2093e-02,  ...,  6.0017e-02,\n",
       "           -7.1587e-02, -2.6322e-02],\n",
       "          [ 2.9706e-01,  1.1742e-01, -1.0902e-01,  ..., -1.0327e-01,\n",
       "           -1.2391e-01, -1.1999e-01],\n",
       "          ...,\n",
       "          [ 7.8288e-02,  7.9756e-02,  5.4602e-02,  ..., -9.5788e-02,\n",
       "           -1.0391e-01,  1.0201e-01],\n",
       "          [-2.2475e-02, -6.4899e-03,  5.4910e-02,  ..., -1.3663e-01,\n",
       "           -2.0156e-01,  5.1816e-02],\n",
       "          [-1.2597e-01, -7.7745e-02, -6.3468e-03,  ..., -1.5777e-01,\n",
       "           -2.4627e-01, -1.1254e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 2.3691e-01,  1.4970e-01,  1.3003e-01,  ..., -2.9236e-02,\n",
       "            4.8729e-02,  7.9474e-02],\n",
       "          [ 2.1306e-01,  1.9401e-01,  1.8742e-01,  ...,  9.0130e-02,\n",
       "            3.9801e-02,  1.0466e-01],\n",
       "          [ 1.6080e-01,  1.7631e-01,  2.0575e-01,  ...,  1.8203e-01,\n",
       "            1.7839e-01,  2.5261e-01],\n",
       "          ...,\n",
       "          [ 3.5792e-02, -3.8938e-02, -5.3120e-02,  ..., -1.5100e-01,\n",
       "           -1.2386e-01,  4.8432e-02],\n",
       "          [ 8.3604e-03,  2.4662e-02,  5.3968e-02,  ..., -4.1126e-02,\n",
       "           -5.4394e-02,  1.0594e-01],\n",
       "          [-6.8381e-02,  5.4439e-02,  1.6895e-02,  ..., -4.4495e-02,\n",
       "           -2.8333e-02,  1.1502e-01]],\n",
       "\n",
       "         [[ 6.5319e-02,  9.7737e-02,  1.6829e-01,  ..., -7.4780e-02,\n",
       "           -2.0227e-01, -1.5846e-01],\n",
       "          [ 4.1519e-02,  7.1749e-02,  1.3596e-01,  ..., -1.9615e-01,\n",
       "           -1.6340e-01, -2.4724e-01],\n",
       "          [ 2.0886e-03,  2.7818e-02,  8.0055e-02,  ..., -1.2460e-01,\n",
       "           -1.7946e-01, -2.2980e-01],\n",
       "          ...,\n",
       "          [-3.2791e-02, -1.2034e-02, -1.3019e-01,  ...,  4.1644e-02,\n",
       "            9.1591e-02,  1.7264e-01],\n",
       "          [-2.5282e-02, -8.1871e-02, -1.2355e-01,  ..., -2.5953e-02,\n",
       "            3.4564e-02,  6.7356e-02],\n",
       "          [-1.7051e-01, -2.0769e-01, -1.8009e-01,  ...,  2.4891e-02,\n",
       "            6.1652e-02, -1.0300e-02]],\n",
       "\n",
       "         [[ 9.7349e-02,  1.7093e-01,  1.3119e-01,  ..., -3.4038e-02,\n",
       "            5.6324e-02,  1.4885e-01],\n",
       "          [ 2.0328e-01,  1.5781e-01,  1.1330e-01,  ...,  7.3556e-02,\n",
       "            8.7688e-02,  7.1262e-02],\n",
       "          [ 2.4585e-01,  1.6153e-01,  6.2243e-02,  ...,  1.2352e-02,\n",
       "            1.0358e-01,  9.1528e-02],\n",
       "          ...,\n",
       "          [ 7.0258e-02,  1.6802e-01,  1.5907e-01,  ...,  4.0108e-01,\n",
       "            3.3519e-01,  1.6902e-01],\n",
       "          [ 1.0487e-01,  7.6007e-02,  4.8084e-02,  ...,  2.7891e-01,\n",
       "            3.1247e-01,  2.4917e-01],\n",
       "          [ 8.7735e-02,  8.0133e-02, -1.4015e-02,  ...,  2.1332e-01,\n",
       "            1.5278e-01,  1.0620e-01]],\n",
       "\n",
       "         [[-1.5205e-02, -5.3501e-02, -1.4612e-01,  ..., -6.8176e-03,\n",
       "            2.5143e-02, -1.1372e-01],\n",
       "          [-8.7158e-03, -4.9878e-02, -8.0779e-02,  ..., -1.9470e-01,\n",
       "           -6.6036e-02, -4.8457e-02],\n",
       "          [-1.0637e-01, -7.8197e-02, -6.0470e-02,  ..., -2.0926e-01,\n",
       "            2.7366e-02,  8.5001e-02],\n",
       "          ...,\n",
       "          [-1.1550e-01,  1.0855e-02, -6.8046e-02,  ..., -1.5240e-01,\n",
       "           -2.0596e-01,  2.9993e-03],\n",
       "          [-1.1345e-01, -3.4180e-02, -6.0055e-02,  ..., -7.2953e-02,\n",
       "           -8.8595e-02,  1.6464e-02],\n",
       "          [-9.1948e-02, -3.0433e-02, -6.9916e-02,  ..., -1.1556e-01,\n",
       "           -5.7535e-03,  1.9420e-03]],\n",
       "\n",
       "         [[-2.7828e-02,  5.0983e-02,  9.2362e-02,  ..., -5.3314e-02,\n",
       "           -6.9344e-02, -5.0849e-03],\n",
       "          [ 3.3206e-02,  6.7785e-02,  3.7003e-02,  ...,  1.1273e-02,\n",
       "            6.6487e-02,  6.3959e-02],\n",
       "          [ 6.9476e-02,  4.9858e-02, -4.2633e-02,  ..., -1.2968e-01,\n",
       "           -1.0150e-01, -1.7002e-01],\n",
       "          ...,\n",
       "          [-1.5384e-01,  3.6990e-03, -8.8675e-02,  ..., -2.2313e-01,\n",
       "           -2.3196e-01, -1.8312e-01],\n",
       "          [-1.8377e-01, -1.2639e-01, -1.8085e-01,  ..., -1.6058e-01,\n",
       "           -1.8776e-01, -1.1020e-01],\n",
       "          [-2.2944e-01, -1.4320e-01, -2.1585e-01,  ..., -1.1249e-01,\n",
       "           -5.1675e-02,  5.6627e-02]]]], device='cuda:0',\n",
       "       grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_batch = torch.rand((64, 3, 256, 256), dtype=torch.float).to(device)\n",
    "out = module.forward(dummy_batch, dummy_batch)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleBranchFarSegModule(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        loss: nn.Module,\n",
    "        optimizer_factory: Callable[[Any], torch.optim.Optimizer],\n",
    "        scheduler_factory: Callable[[Any], torch.optim.lr_scheduler.LRScheduler] | None = None,\n",
    "        class_weights: Tensor | None = None,\n",
    "    ):\n",
    "        super(DoubleBranchFarSegModule, self).__init__()\n",
    "        # n classes\n",
    "        n_classes = 5\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        self.class_weights = class_weights\n",
    "\n",
    "        self.save_hyperparameters(ignore=[\"model\", \"loss\"])\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "        self.optimizer_factory = optimizer_factory\n",
    "        self.scheduler_factory = scheduler_factory\n",
    "\n",
    "        # loss function\n",
    "        self.loss_fn = loss\n",
    "        # metrics\n",
    "        self.accuracy_loc = torchmetrics.classification.BinaryAccuracy()\n",
    "        self.iou_loc = torchmetrics.segmentation.MeanIoU(num_classes=2)\n",
    "\n",
    "        self.f1 = torchmetrics.classification.MulticlassF1Score(num_classes=n_classes)\n",
    "        self.precision = torchmetrics.classification.MulticlassPrecision(num_classes=n_classes)\n",
    "        self.recall = torchmetrics.classification.MulticlassRecall(num_classes=n_classes)\n",
    "        self.iou = torchmetrics.segmentation.MeanIoU(num_classes=n_classes)\n",
    "\n",
    "        self.f1_per_class = torchmetrics.classification.MulticlassF1Score(num_classes=n_classes, average=\"none\")\n",
    "        self.precision_per_class = torchmetrics.classification.MulticlassPrecision(\n",
    "            num_classes=n_classes, average=\"none\"\n",
    "        )\n",
    "        self.recall_per_class = torchmetrics.classification.MulticlassRecall(num_classes=n_classes, average=\"none\")\n",
    "        self.iou_per_class = torchmetrics.segmentation.MeanIoU(num_classes=n_classes, per_class=True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(x)  # type: ignore[no-any-return]\n",
    "\n",
    "    def loss(\n",
    "        self, images_pre: Tensor, masks_pre: Tensor, images_post: Tensor, masks_post: Tensor\n",
    "    ) -> tuple[Tensor, Tensor]:\n",
    "        preds = self.forward(torch.cat([images_pre, images_post], dim=1))\n",
    "        if self.class_weights is not None:\n",
    "            # per-class loss in unweighted!\n",
    "            class_loss = torch.stack(\n",
    "                [self.loss_fn(preds[:, i, ...], masks_post.to(torch.float)[:, i, ...]) for i in range(preds.shape[1])]\n",
    "            )\n",
    "            loss = class_loss.dot(self.class_weights).sum()\n",
    "        else:\n",
    "            loss = self.loss_fn(preds, masks_post.to(torch.float))\n",
    "            class_loss = Tensor([0, 0, 0, 0, 0])\n",
    "\n",
    "        return loss, class_loss\n",
    "\n",
    "    def training_step(self, batch: list[Tensor], batch_idx: int) -> Tensor:\n",
    "        loss, class_loss = self.loss(*batch)\n",
    "\n",
    "        class_loss_dict = {f\"train_loss_{i}\": loss_val for i, loss_val in enumerate(class_loss)}\n",
    "        self.log_dict(class_loss_dict | {\"train_loss\": loss}, prog_bar=True, batch_size=batch.shape[0])\n",
    "        return loss  # type: ignore[no-any-return]\n",
    "\n",
    "    def validation_step(self, batch: list[Tensor], batch_idx: int):  # type: ignore[no-untyped-def]\n",
    "        with torch.no_grad():\n",
    "            images_pre, _, images_post, masks_post = batch\n",
    "\n",
    "            cls_preds = self.forward(torch.cat([images_pre, images_post], dim=1))\n",
    "            cls_preds_masks = F.one_hot(cls_preds.argmax(dim=1), num_classes=self.n_classes).moveaxis(-1, 1)\n",
    "\n",
    "            loss, class_loss = self.loss(*batch)\n",
    "\n",
    "            log_dict = (\n",
    "                {\n",
    "                    \"acc_loc\": self.accuracy_loc(\n",
    "                        cls_preds.argmax(dim=1).gt(0).to(torch.float), masks_post.argmax(dim=1).gt(0).to(torch.float)\n",
    "                    ),\n",
    "                    \"iou_loc\": self.iou_loc(\n",
    "                        F.one_hot(cls_preds.argmax(dim=1).gt(0).to(torch.long), num_classes=2).moveaxis(-1, 1),\n",
    "                        F.one_hot(masks_post.argmax(dim=1).gt(0).to(torch.long), num_classes=2).moveaxis(-1, 1),\n",
    "                    ),\n",
    "                }\n",
    "                | {\n",
    "                    name: getattr(self, name)(cls_preds.argmax(dim=1), masks_post.argmax(dim=1))\n",
    "                    for name in [\"f1\", \"precision\", \"recall\"]\n",
    "                }\n",
    "                | {\"iou\": self.iou(cls_preds_masks, masks_post.to(torch.uint8))}\n",
    "                | {\n",
    "                    f\"{name}_{i}\": val\n",
    "                    for name, vec in {\n",
    "                        name: getattr(self, f\"{name}_per_class\")(cls_preds.argmax(dim=1), masks_post.argmax(dim=1))\n",
    "                        for name in [\"f1\", \"precision\", \"recall\"]\n",
    "                    }.items()\n",
    "                    for i, val in enumerate(vec)\n",
    "                }\n",
    "                | {\n",
    "                    f\"iou_{i}\": val\n",
    "                    for i, val in enumerate(self.iou_per_class(cls_preds_masks, masks_post.to(torch.uint8)))\n",
    "                }\n",
    "                | {f\"val_loss_{i}\": loss_val for i, loss_val in enumerate(class_loss)}\n",
    "                | {\"val_loss\": loss}\n",
    "            )\n",
    "            self.log_dict(log_dict, prog_bar=True, batch_size=batch.shape[0])\n",
    "\n",
    "            return log_dict\n",
    "\n",
    "    def configure_optimizers(self):  # type: ignore[no-untyped-def]\n",
    "        optimizer = self.optimizer_factory(self.model.parameters())\n",
    "        if self.scheduler_factory:\n",
    "            scheduler = self.scheduler_factory(optimizer)\n",
    "            return [optimizer], [scheduler]\n",
    "        else:\n",
    "            return optimizer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
